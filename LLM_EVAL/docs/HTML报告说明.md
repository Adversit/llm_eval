# HTML 评估报告说明文档

## 概述

系统现已支持生成标准化的 HTML 格式评估报告，符合"大模型能力评估表（知识与推理能力）"的规范要求。

## 报告内容

### 评估维度

#### 1. 大模型内部知识能力
- **定义**：衡量模型在无外部参考内容情况下的知识储备和问答准确性
- **评估方法**：基于 Stage1 评估结果，计算最终正确率
- **单位**：百分比（%）
- **标准要求**：综合正确率 ≥ 60%

#### 2. 大模型推理能力
- **定义**：衡量模型的逻辑推理、分析和内容理解能力
- **评估方法**：综合 Stage1 和 Stage2 的推理得分，取平均值
- **单位**：分（百分制）
- **标准要求**：推理得分 ≥ 60分

### 评分标准

采用百分制评分体系（0-100分）：
- **基础分值**：0-60分，评估基本能力
- **卓越加分**：0-40分，评估优秀表现

### 结论判定标准

根据得分自动判定检验结论：

| 得分范围 | 结论 | 说明 |
|---------|------|------|
| ≥ 80 | 通过 | 表现优秀 |
| 60-79 | 基本通过 | 达到合格标准 |
| < 60 | 不通过 | 未达到基本要求 |

## 报告字段说明

### 1. 序号
评估项目的编号（1-2）

### 2. 被评估模型
待测试的大语言模型名称（从系统配置中自动获取）

### 3. 评估模型
用于对模型输出进行评分的参考模型名称（从评估参数中获取）

### 4. 能力项
评估的具体能力维度：
- 大模型内部知识能力
- 大模型推理能力

### 5. 单位
- 知识能力：%（百分比）
- 推理能力：分（百分制）

### 6. 标准要求
各能力项的合格标准：
- 知识能力：综合正确率 ≥ 60%
- 推理能力：推理得分 ≥ 60分

### 7. 检验结果
实际测评得到的分数或百分比：
- 知识能力：显示为 "XX.XX%"
- 推理能力：显示为 "XX.XX分"

### 8. 检验结论
根据检验结果自动判定：
- **通过**（绿色）：得分 ≥ 80
- **基本通过**（橙色）：60 ≤ 得分 < 80
- **不通过**（红色）：得分 < 60

## 使用方法

### 在 Streamlit 界面中使用

1. 完成模型评估后，进入"📊 结果分析"页面
2. 在每个文件的分析结果下方，点击"📋 下载评估表 (HTML)"按钮
3. 报告将自动下载为 HTML 文件

### 在代码中使用

```python
from utils.html_report_generator import HTMLReportGenerator

# 初始化报告生成器
generator = HTMLReportGenerator()

# 准备数据
analysis_data = {
    "model_name": "FinLLM-A",
    "final_accuracy_rate": 75.5,
    "evaluation_info": {
        # ... 评估信息
    }
}

evaluation_params = {
    "eval_model_name": "GPT-4"
}

# 生成报告
html_content = generator.generate_report(analysis_data, evaluation_params)

# 保存报告
from pathlib import Path
output_path = Path("evaluation_report.html")
generator.save_report(html_content, output_path)
```

## 报告特性

### 1. 自适应设计
- 支持响应式布局，在不同设备上均可正常显示
- 适配打印格式，可直接打印为纸质报告

### 2. 视觉标识
- 使用颜色标识不同的结论等级
- 清晰的表格布局，易于阅读

### 3. 详细说明
- 包含填写说明，便于理解各字段含义
- 包含评估说明，详细解释评估方法和标准

### 4. 时间戳
- 自动添加报告生成时间
- 文件名包含时间戳，避免覆盖

## 技术细节

### 数据来源

#### 知识能力得分
从 `analysis_data` 中的 `final_accuracy_rate` 字段获取

#### 推理能力得分
根据评估类型自动计算：
- **单轮评估**：从 Stage1 和 Stage2 的 `score_distribution` 中获取 `avg_reasoning_score`
- **多轮评估**：从 `aggregated_statistics` 中获取 `avg_reasoning_score`
- **计算方法**：如果存在 Stage2，取 Stage1 和 Stage2 的平均值；否则只取 Stage1 的值

### 自动化特性

1. **数据提取**：自动从评估结果中提取所需数据
2. **结论判定**：根据分数自动判定检验结论
3. **颜色标记**：根据结论自动应用对应的颜色样式
4. **时间标记**：自动添加生成时间戳

## 示例报告

生成的 HTML 报告示例内容：

```
大模型能力评估表（知识与推理能力）

生成时间：2025年01月15日 14:30:25

| 序号 | 被评估模型 | 评估模型 | 能力项 | 单位 | 标准要求 | 检验结果 | 检验结论 |
|------|-----------|---------|--------|------|---------|---------|---------|
| 1 | FinLLM-A | GPT-4 | 大模型内部知识能力 | % | 综合正确率 ≥ 60% | 75.50% | 基本通过 |
| 2 | FinLLM-A | GPT-4 | 大模型推理能力 | 分 | 推理得分 ≥ 60分 | 70.20分 | 基本通过 |
```

## 注意事项

1. **评估参数保存**：确保在评估开始时正确保存 `evaluation_params` 到 `session_state`
2. **数据完整性**：生成报告前需要完成完整的评估流程
3. **模型名称**：确保在信息填写界面正确填写被评估模型名称
4. **评估模型**：评估模型名称从评估参数中自动获取，默认为系统配置的评估模型

## 更新日志

### v1.0.0 (2025-01-15)
- ✨ 新增 HTML 评估报告生成功能
- ✨ 支持自动计算知识能力和推理能力得分
- ✨ 支持自动判定检验结论
- ✨ 支持颜色标识不同等级
- ✨ 集成到 Streamlit 界面的下载功能
- 📝 完善评分标准说明和字段定义
