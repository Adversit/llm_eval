import streamlit as st
import json
import pandas as pd
from pathlib import Path
from PIL import Image
import os
import sys
from typing import Dict, List, Any, Optional
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(str(Path(__file__).parent.parent))
from utils.file_manager_singleton import get_file_manager, reset_file_manager_for_new_test
from utils.report_generator import ReportGenerator
from utils.html_report_generator import HTMLReportGenerator

class ResultAnalysisInterface:
    """ç»“æœåˆ†æç•Œé¢"""
    
    def __init__(self):
        """åˆå§‹åŒ–ç»“æœåˆ†æç•Œé¢"""
        self.file_manager = get_file_manager()
        self.report_generator = ReportGenerator()
        self.html_report_generator = HTMLReportGenerator()
    
    def render(self):
        """æ¸²æŸ“ç»“æœåˆ†æç•Œé¢"""
        st.header("ğŸ“Š ç»“æœåˆ†æ")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰è¯„ä¼°ç»“æœ
        if not st.session_state.get('evaluation_completed', False):
            st.warning("âš ï¸ è¯·å…ˆå®Œæˆè¯„ä¼°è¿‡ç¨‹")
            return
        
        if 'evaluation_results' not in st.session_state:
            st.error("âŒ æœªæ‰¾åˆ°è¯„ä¼°ç»“æœæ•°æ®")
            return
        
        results = st.session_state.evaluation_results
        model_name = results['model_name']
        file_names = results['file_names']
        enable_multi_file = results['enable_multi_file']
        
        # æ˜¾ç¤ºå•æ–‡ä»¶ç»“æœ
        self._display_single_file_results(model_name, file_names)
        
        # å¦‚æœæœ‰å¤šä¸ªæ–‡ä»¶ï¼Œæ˜¾ç¤ºå¤šæ–‡ä»¶æ±‡æ€»ç»“æœ
        if enable_multi_file and len(file_names) > 1:
            st.markdown("---")
            self._display_multi_file_results(model_name)
        
        # é‡æ–°å¼€å§‹æµ‹è¯„æŒ‰é’®
        st.markdown("---")
        self._render_restart_button()
    
    def _display_single_file_results(self, model_name: str, file_names: List[str]):
        """æ˜¾ç¤ºå•æ–‡ä»¶ç»“æœ"""
        st.subheader("ğŸ“„ å•æ–‡ä»¶åˆ†æç»“æœ")
        
        # å¦‚æœæœ‰å¤šä¸ªæ–‡ä»¶ï¼Œä½¿ç”¨é€‰é¡¹å¡æ˜¾ç¤º
        if len(file_names) > 1:
            tabs = st.tabs([f"ğŸ“„ {name}" for name in file_names])
            
            for i, (tab, file_name) in enumerate(zip(tabs, file_names)):
                with tab:
                    self._display_file_analysis(model_name, file_name)
        else:
            # å•ä¸ªæ–‡ä»¶ç›´æ¥æ˜¾ç¤º
            file_name = file_names[0]
            self._display_file_analysis(model_name, file_name)
    
    def _display_file_analysis(self, model_name: str, file_name: str):
        """æ˜¾ç¤ºå•ä¸ªæ–‡ä»¶çš„åˆ†æç»“æœ"""
        # ä½¿ç”¨FileManageræŸ¥æ‰¾æœ€æ–°çš„æ—¶é—´æˆ³ç›®å½•
        timestamped_dir = self.file_manager.find_latest_timestamp_dir(model_name)
        if not timestamped_dir:
            st.error(f"âŒ æœªæ‰¾åˆ°æ¨¡å‹ {model_name} çš„æ—¶é—´æˆ³ç›®å½•")
            return

        # è¯»å–åˆ†ææ–‡ä»¶
        analysis_path = timestamped_dir / file_name / f"{file_name}_analysis.json"

        if not analysis_path.exists():
            st.error(f"âŒ æœªæ‰¾åˆ°æ–‡ä»¶ {file_name} çš„åˆ†æç»“æœ")
            return

        try:
            with open(analysis_path, 'r', encoding='utf-8') as f:
                content = f.read().strip()
                if not content:
                    st.error(f"âŒ åˆ†ææ–‡ä»¶ {analysis_path} ä¸ºç©º")
                    return
                analysis_data = json.loads(content)
        except json.JSONDecodeError as e:
            st.error(f"âŒ åˆ†ææ–‡ä»¶æ ¼å¼é”™è¯¯: {str(e)}")
            st.error(f"æ–‡ä»¶è·¯å¾„: {analysis_path}")
            return
        except Exception as e:
            st.error(f"âŒ è¯»å–åˆ†ææ–‡ä»¶å¤±è´¥: {str(e)}")
            st.error(f"æ–‡ä»¶è·¯å¾„: {analysis_path}")
            return

        # æ˜¾ç¤ºä¸‹è½½æŒ‰é’®ï¼ˆåœ¨è¡¨æ ¼ä¸Šæ–¹ï¼‰
        self._render_single_file_download(model_name, file_name, analysis_data, timestamped_dir)

        # æ˜¾ç¤ºæ™ºèƒ½åˆ†ææŠ¥å‘Šï¼ˆå¯æŠ˜å ï¼‰- æš‚æ—¶ç¦ç”¨
        # with st.expander("ğŸ“‹ æŸ¥çœ‹æ™ºèƒ½åˆ†ææŠ¥å‘Š", expanded=False):
        #     try:
        #         report_md = self.report_generator.generate_analysis_report(analysis_data)
        #         st.markdown(report_md)
        #     except Exception as e:
        #         st.error(f"âŒ ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {str(e)}")

        # æ˜¾ç¤ºåˆ†æè¡¨æ ¼
        self._display_analysis_table(analysis_data, f"{file_name} åˆ†æç»“æœ")

        # æ˜¾ç¤ºå¯è§†åŒ–å›¾ç‰‡
        self._display_visualizations(model_name, file_name)
    
    def _display_multi_file_results(self, model_name: str):
        """æ˜¾ç¤ºå¤šæ–‡ä»¶æ±‡æ€»ç»“æœ"""
        st.subheader("ğŸ“Š å¤šæ–‡ä»¶æ±‡æ€»åˆ†æ")
        
        # ä½¿ç”¨FileManageræŸ¥æ‰¾æœ€æ–°çš„æ—¶é—´æˆ³ç›®å½•
        timestamped_dir = self.file_manager.find_latest_timestamp_dir(model_name)
        if not timestamped_dir:
            st.error(f"âŒ æœªæ‰¾åˆ°æ¨¡å‹ {model_name} çš„æ—¶é—´æˆ³ç›®å½•")
            return
        
        # è¯»å–å¤šæ–‡ä»¶æ±‡æ€»åˆ†æ
        multi_analysis_path = timestamped_dir / "multi_file" / "multi_analysis.json"
        
        if not multi_analysis_path.exists():
            st.error("âŒ æœªæ‰¾åˆ°å¤šæ–‡ä»¶æ±‡æ€»åˆ†æç»“æœ")
            return
        
        try:
            with open(multi_analysis_path, 'r', encoding='utf-8') as f:
                content = f.read().strip()
                if not content:
                    st.error(f"âŒ å¤šæ–‡ä»¶æ±‡æ€»åˆ†ææ–‡ä»¶ä¸ºç©º")
                    return
                multi_analysis_data = json.loads(content)
        except json.JSONDecodeError as e:
            st.error(f"âŒ å¤šæ–‡ä»¶æ±‡æ€»åˆ†ææ–‡ä»¶æ ¼å¼é”™è¯¯: {str(e)}")
            st.error(f"æ–‡ä»¶è·¯å¾„: {multi_analysis_path}")
            return
        except Exception as e:
            st.error(f"âŒ è¯»å–å¤šæ–‡ä»¶æ±‡æ€»åˆ†æå¤±è´¥: {str(e)}")
            st.error(f"æ–‡ä»¶è·¯å¾„: {multi_analysis_path}")
            return
        
        # æ˜¾ç¤ºæ±‡æ€»åˆ†æè¡¨æ ¼ï¼ˆä¸æ˜¾ç¤ºè¯„ä¼°ç±»å‹ï¼‰
        self._display_multi_file_analysis_table(multi_analysis_data, "å¤šæ–‡ä»¶æ±‡æ€»åˆ†æç»“æœ")
        
        # æ˜¾ç¤ºä¸‹è½½æŒ‰é’®
        self._render_complete_download(model_name, file_names)

        # æ˜¾ç¤ºå¤šæ–‡ä»¶æ±‡æ€»å¯è§†åŒ–å›¾ç‰‡
        self._display_multi_file_visualizations(model_name)

    def _render_single_file_download(self, model_name: str, file_name: str,
                                     analysis_data: Dict[str, Any], timestamped_dir: Path):
        """æ¸²æŸ“å•ä¸ªæ–‡ä»¶çš„ä¸‹è½½æŒ‰é’®"""
        st.markdown("---")

        col1, col2 = st.columns(2)

        with col1:
            # ä¸‹è½½åˆ†ææŠ¥å‘Š - æš‚æ—¶ç¦ç”¨
            # try:
            #     report_md = self.report_generator.generate_analysis_report(analysis_data)
            #     st.download_button(
            #         label="ğŸ“„ ä¸‹è½½åˆ†ææŠ¥å‘Š (Markdown)",
            #         data=report_md,
            #         file_name=f"{file_name}_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md",
            #         mime="text/markdown",
            #         use_container_width=True,
            #         key=f"download_report_{file_name}"
            #     )
            # except Exception as e:
            #     st.error(f"âŒ ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {str(e)}")
            # ä¸‹è½½HTMLè¯„ä¼°è¡¨
            try:
                # è·å–è¯„ä¼°å‚æ•°
                evaluation_params = st.session_state.get('evaluation_params', {})

                # ç”ŸæˆHTMLæŠ¥å‘Š
                html_content = self.html_report_generator.generate_report(
                    analysis_data, evaluation_params
                )

                st.download_button(
                    label="ğŸ“‹ ä¸‹è½½è¯„ä¼°è¡¨ (HTML)",
                    data=html_content,
                    file_name=f"{file_name}_evaluation_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html",
                    mime="text/html",
                    use_container_width=True,
                    key=f"download_html_{file_name}"
                )
            except Exception as e:
                st.error(f"âŒ ç”ŸæˆHTMLæŠ¥å‘Šå¤±è´¥: {str(e)}")

        with col2:
            # ä¸‹è½½åŸå§‹æ•°æ®
            try:
                st.download_button(
                    label="ğŸ“Š ä¸‹è½½åŸå§‹æ•°æ® (JSON)",
                    data=json.dumps(analysis_data, ensure_ascii=False, indent=2),
                    file_name=f"{file_name}_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                    mime="application/json",
                    use_container_width=True,
                    key=f"download_json_{file_name}"
                )
            except Exception as e:
                st.error(f"âŒ ä¸‹è½½æ•°æ®å¤±è´¥: {str(e)}")

        st.markdown("---")

    def _render_complete_download(self, model_name: str, file_names: List[str]):
        """æ¸²æŸ“å®Œæ•´æ‰“åŒ…ä¸‹è½½æŒ‰é’®"""
        st.markdown("---")
        st.subheader("ğŸ“¦ ä¸‹è½½å®Œæ•´è¯„ä¼°åŒ…")
        st.write("ä¸‹è½½åŒ…å«æ‰€æœ‰æŠ¥å‘Šã€æ•°æ®å’Œå¯è§†åŒ–å›¾è¡¨çš„å®Œæ•´ZIPæ–‡ä»¶")

        timestamped_dir = self.file_manager.find_latest_timestamp_dir(model_name)
        if not timestamped_dir:
            st.error("âŒ æœªæ‰¾åˆ°æ—¶é—´æˆ³ç›®å½•")
            return

        try:
            zip_buffer = self.report_generator.create_download_package(
                model_name, file_names, timestamped_dir
            )

            st.download_button(
                label="ğŸ“¥ ä¸‹è½½å®Œæ•´è¯„ä¼°åŒ… (ZIP)",
                data=zip_buffer,
                file_name=f"{model_name}_evaluation_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip",
                mime="application/zip",
                use_container_width=True,
                key="download_complete_package"
            )
        except Exception as e:
            st.error(f"âŒ åˆ›å»ºä¸‹è½½åŒ…å¤±è´¥: {str(e)}")

        st.markdown("---")

    def _display_analysis_table(self, analysis_data: Dict[str, Any], title: str):
        """æ˜¾ç¤ºåˆ†æç»“æœè¡¨æ ¼"""
        st.write(f"**{title}**")
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºå¤šè½®è¯„ä¼°
        evaluation_info = analysis_data.get('evaluation_info', {})
        is_multi_round = evaluation_info.get('is_multi_round_evaluation', False)
        
        # æ˜¾ç¤ºé‡è¦ä¿¡æ¯ï¼ˆå¤§å­—ä½“ï¼‰
        col1, col2, col3 = st.columns(3)
        
        with col1:
            # æ˜¾ç¤ºæ–‡ä»¶åç§°ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if 'file_name' in analysis_data:
                st.markdown(f"<div style='background-color: #f0f2f6; padding: 10px; border-radius: 5px; margin-bottom: 10px;'>"
                           f"<p style='font-size: 18px; font-weight: bold; margin: 0; color: #1f77b4;'>ğŸ“„ æ–‡ä»¶åç§°</p>"
                           f"<p style='font-size: 16px; margin: 5px 0 0 0; color: #333;'>{analysis_data.get('file_name', 'N/A')}</p>"
                           f"</div>", unsafe_allow_html=True)
        
        with col2:
            # æ˜¾ç¤ºæ–‡ä»¶æ•°é‡ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if 'file_count' in analysis_data:
                st.markdown(f"<div style='background-color: #f0f2f6; padding: 10px; border-radius: 5px; margin-bottom: 10px;'>"
                           f"<p style='font-size: 18px; font-weight: bold; margin: 0; color: #1f77b4;'>ğŸ“Š æ–‡ä»¶æ•°é‡</p>"
                           f"<p style='font-size: 16px; margin: 5px 0 0 0; color: #333;'>{analysis_data.get('file_count', 'N/A')}</p>"
                           f"</div>", unsafe_allow_html=True)
        
        with col3:
            # ç¬¬ä¸‰åˆ—ç•™ç©ºæˆ–æ˜¾ç¤ºå…¶ä»–ä¿¡æ¯
            pass
        
        # è½®æ¬¡ä¿¡æ¯å·²åˆ é™¤
        
        # æ˜¾ç¤ºåŸºæœ¬ç»Ÿè®¡è¡¨æ ¼
        self._display_basic_statistics_table(analysis_data)
        
        # å¦‚æœæ˜¯å¤šè½®è¯„ä¼°ï¼Œæ˜¾ç¤ºè¯¦ç»†è½®æ¬¡è¡¨æ ¼
        if is_multi_round:
            self._display_round_details_table(analysis_data)
    

    
    def _display_basic_statistics_table(self, analysis_data: Dict[str, Any]):
        """æ˜¾ç¤ºåŸºæœ¬ç»Ÿè®¡è¡¨æ ¼"""
        st.write("**ğŸ“Š æœ€ç»ˆç»Ÿè®¡ç»“æœ**")
        
        # åˆ›å»ºè¡¨æ ¼æ•°æ®
        table_data = []
        
        # åŸºæœ¬ä¿¡æ¯
        table_data.append(["æ¨¡å‹åç§°", analysis_data.get('model_name', 'N/A')])
        
        if 'processed_files' in analysis_data:
            files_str = ", ".join(analysis_data['processed_files'])
            table_data.append(["å¤„ç†æ–‡ä»¶", files_str])
        
        # åˆ†éš”çº¿
        table_data.append(["---", "---"])
        
        # ç»Ÿè®¡ç»“æœ
        table_data.append(["æ­£ç¡®å›ç­”æ•°", str(analysis_data.get('final_correct_answers', 0))])
        table_data.append(["æ¨ç†é”™è¯¯æ•°", str(analysis_data.get('final_reasoning_errors', 0))])
        table_data.append(["çŸ¥è¯†ç¼ºå¤±æ•°", str(analysis_data.get('final_knowledge_deficiency', 0))])
        table_data.append(["èƒ½åŠ›ä¸è¶³æ•°", str(analysis_data.get('final_capability_insufficient', 0))])
        
        # åˆ†éš”çº¿
        table_data.append(["---", "---"])
        
        # æ¯”ä¾‹ç»Ÿè®¡
        table_data.append(["æ­£ç¡®ç‡", f"{analysis_data.get('final_accuracy_rate', 0):.2f}%"])
        table_data.append(["æ¨ç†é”™è¯¯ç‡", f"{analysis_data.get('final_reasoning_error_rate', 0):.2f}%"])
        table_data.append(["çŸ¥è¯†ç¼ºå¤±ç‡", f"{analysis_data.get('final_knowledge_deficiency_rate', 0):.2f}%"])
        table_data.append(["èƒ½åŠ›ä¸è¶³ç‡", f"{analysis_data.get('final_capability_insufficient_rate', 0):.2f}%"])
        
        # åˆ›å»ºDataFrameå¹¶æ˜¾ç¤º
        df = pd.DataFrame(table_data, columns=["æŒ‡æ ‡", "å€¼"])
        st.dataframe(df, use_container_width=True, hide_index=True)
    
    def _display_round_details_table(self, analysis_data: Dict[str, Any]):
        """æ˜¾ç¤ºè½®æ¬¡è¯¦ç»†ä¿¡æ¯è¡¨æ ¼"""
        st.write("**ğŸ” å„è½®æ¬¡è¯¦ç»†ç»“æœ**")
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºå¤šè½®è¯„ä¼°
        evaluation_info = analysis_data.get('evaluation_info', {})
        is_multi_round = evaluation_info.get('is_multi_round_evaluation', False)
        
        if not is_multi_round:
            st.info("ğŸ“ å½“å‰ä¸ºå•è½®è¯„ä¼°ï¼Œæ— è½®æ¬¡è¯¦ç»†æ•°æ®")
            return
        
        # è·å–æ–‡ä»¶ä¿¡æ¯
        model_name = analysis_data.get('model_name')
        file_name = analysis_data.get('file_name')
        
        if not model_name or not file_name:
            st.info("ğŸ“ ç¼ºå°‘å¿…è¦çš„æ–‡ä»¶ä¿¡æ¯ï¼Œæ— æ³•æ˜¾ç¤ºè½®æ¬¡è¯¦æƒ…")
            return
        
        # ä½¿ç”¨FileManageræŸ¥æ‰¾æœ€æ–°çš„æ—¶é—´æˆ³ç›®å½•
        timestamped_dir = self.file_manager.find_latest_timestamp_dir(model_name)
        if not timestamped_dir:
            st.error(f"âŒ æœªæ‰¾åˆ°æ¨¡å‹ {model_name} çš„æ—¶é—´æˆ³ç›®å½•")
            return
        
        base_dir = timestamped_dir / file_name
        
        # åˆ›å»ºé€‰é¡¹å¡æ¥åˆ†åˆ«æ˜¾ç¤ºStage1å’ŒStage2çš„è½®æ¬¡è¯¦æƒ…
        stage_tabs = []
        stage_data = []
        
        # æ£€æŸ¥Stage1å¤šè½®åˆ†ææ–‡ä»¶
        stage1_multi_path = base_dir / "stage1_multi_round_analysis.json"
        if stage1_multi_path.exists():
            try:
                with open(stage1_multi_path, 'r', encoding='utf-8') as f:
                    stage1_data = json.load(f)
                if stage1_data and stage1_data.get('individual_results'):
                    stage_tabs.append("ğŸ“Š Stage1 è½®æ¬¡è¯¦æƒ…")
                    stage_data.append(('stage1', stage1_data))
            except Exception as e:
                st.warning(f"âš ï¸ è¯»å–Stage1å¤šè½®åˆ†ææ–‡ä»¶å¤±è´¥: {str(e)}")
        
        # æ£€æŸ¥Stage2å¤šè½®åˆ†ææ–‡ä»¶
        stage2_multi_path = base_dir / "stage2_multi_round_analysis.json"
        if stage2_multi_path.exists():
            try:
                with open(stage2_multi_path, 'r', encoding='utf-8') as f:
                    stage2_data = json.load(f)
                if stage2_data and stage2_data.get('individual_results'):
                    stage_tabs.append("ğŸ“Š Stage2 è½®æ¬¡è¯¦æƒ…")
                    stage_data.append(('stage2', stage2_data))
            except Exception as e:
                st.warning(f"âš ï¸ è¯»å–Stage2å¤šè½®åˆ†ææ–‡ä»¶å¤±è´¥: {str(e)}")
        
        if not stage_tabs:
            st.info("ğŸ“ æš‚æ— è¯¦ç»†è½®æ¬¡æ•°æ®")
            return
        
        # åˆ›å»ºé€‰é¡¹å¡
        tabs = st.tabs(stage_tabs)
        
        for tab, (stage_name, data) in zip(tabs, stage_data):
            with tab:
                self._display_stage_round_table(stage_name, data)
    
    def _display_stage_round_table(self, stage_name: str, stage_data: Dict[str, Any]):
        """æ˜¾ç¤ºç‰¹å®šé˜¶æ®µçš„è½®æ¬¡è¡¨æ ¼"""
        individual_results = stage_data.get('individual_results', [])
        
        if not individual_results:
            st.info(f"ğŸ“ {stage_name.upper()} æš‚æ— è½®æ¬¡æ•°æ®")
            return
        
        # å‡†å¤‡è¡¨æ ¼æ•°æ®
        round_table_data = []
        
        for result in individual_results:
            round_num = result.get('round_number', 'N/A')
            stats = result.get('statistics', {})
            score_dist = result.get('score_distribution', {})
            timestamp = result.get('evaluation_timestamp', 'N/A')
            
            if stage_name == 'stage1':
                # Stage1 çš„ç»Ÿè®¡å­—æ®µ
                correct = stats.get('correct_answers', 0)
                reasoning_errors = stats.get('reasoning_errors', 0)
                need_retest = stats.get('need_retest', 0)
                accuracy_rate = stats.get('accuracy_rate', 0)
                
                round_table_data.append([
                    f"ç¬¬{round_num}è½®",
                    str(correct),
                    str(reasoning_errors),
                    str(need_retest),
                    f"{accuracy_rate:.2f}%",
                    f"{score_dist.get('avg_answer_score', 0):.2f}",
                    f"{score_dist.get('avg_reasoning_score', 0):.2f}",
                    timestamp.split(' ')[0] if timestamp != 'N/A' else 'N/A'
                ])
            
            elif stage_name == 'stage2':
                # Stage2 çš„ç»Ÿè®¡å­—æ®µ
                knowledge_def = stats.get('knowledge_deficiency', 0)
                reasoning_errors = stats.get('reasoning_errors', 0)
                capability_insuf = stats.get('capability_insufficient', 0)
                knowledge_rate = stats.get('knowledge_deficiency_rate', 0)
                
                round_table_data.append([
                    f"ç¬¬{round_num}è½®",
                    str(knowledge_def),
                    str(reasoning_errors),
                    str(capability_insuf),
                    f"{knowledge_rate:.2f}%",
                    f"{score_dist.get('avg_answer_score', 0):.2f}",
                    f"{score_dist.get('avg_reasoning_score', 0):.2f}",
                    timestamp.split(' ')[0] if timestamp != 'N/A' else 'N/A'
                ])
        
        # åˆ›å»ºDataFrame
        if stage_name == 'stage1':
            columns = ["è½®æ¬¡", "æ­£ç¡®å›ç­”", "æ¨ç†é”™è¯¯", "éœ€è¦é‡æµ‹", "å‡†ç¡®ç‡", "å¹³å‡ç­”æ¡ˆåˆ†æ•°", "å¹³å‡æ¨ç†åˆ†æ•°", "è¯„ä¼°æ—¥æœŸ"]
        else:  # stage2
            columns = ["è½®æ¬¡", "çŸ¥è¯†ç¼ºå¤±", "æ¨ç†é”™è¯¯", "èƒ½åŠ›ä¸è¶³", "çŸ¥è¯†ç¼ºå¤±ç‡", "å¹³å‡ç­”æ¡ˆåˆ†æ•°", "å¹³å‡æ¨ç†åˆ†æ•°", "è¯„ä¼°æ—¥æœŸ"]
        
        df = pd.DataFrame(round_table_data, columns=columns)
        st.dataframe(df, use_container_width=True, hide_index=True)
        
        # æ˜¾ç¤ºæ–¹å·®ç»Ÿè®¡ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        self._display_variance_statistics(stage_name, stage_data)
    
    def _display_visualizations(self, model_name: str, file_name: str):
        """æ˜¾ç¤ºå•æ–‡ä»¶çš„å¯è§†åŒ–å›¾ç‰‡"""
        st.write("**ğŸ“ˆ å¯è§†åŒ–å›¾è¡¨**")
        
        # ä½¿ç”¨FileManageræŸ¥æ‰¾æœ€æ–°çš„æ—¶é—´æˆ³ç›®å½•
        timestamped_dir = self.file_manager.find_latest_timestamp_dir(model_name)
        if not timestamped_dir:
            st.warning("âš ï¸ æœªæ‰¾åˆ°æ—¶é—´æˆ³ç›®å½•")
            return
        
        # å›¾ç‰‡åœ¨æ—¶é—´æˆ³ç›®å½•/æ–‡ä»¶åç›®å½•/visualizationsä¸‹
        viz_dir = timestamped_dir / file_name / "visualizations"
        
        if not viz_dir.exists():
            st.warning("âš ï¸ æœªæ‰¾åˆ°å¯è§†åŒ–å›¾ç‰‡ç›®å½•")
            return
        
        # æŸ¥æ‰¾å›¾ç‰‡æ–‡ä»¶
        image_files = []
        for ext in ['*.png', '*.jpg', '*.jpeg']:
            image_files.extend(viz_dir.glob(ext))
        
        if not image_files:
            st.warning("âš ï¸ æœªæ‰¾åˆ°å¯è§†åŒ–å›¾ç‰‡")
            return
        
        # æ˜¾ç¤ºå›¾ç‰‡
        cols = st.columns(2)
        
        for i, image_path in enumerate(sorted(image_files)):
            try:
                image = Image.open(image_path)
                col_idx = i % 2
                
                with cols[col_idx]:
                    st.image(image, width=None)
                    # ä½¿ç”¨è‡ªå®šä¹‰HTMLæ˜¾ç¤ºæ›´å¤§çš„æ–‡ä»¶åæ ‡ç­¾
                    st.markdown(f"<p style='text-align: center; font-size: 16px; font-weight: bold; margin-top: 5px; color: #333;'>{image_path.stem}</p>", unsafe_allow_html=True)
            except Exception as e:
                st.error(f"âŒ æ— æ³•æ˜¾ç¤ºå›¾ç‰‡ {image_path.name}: {str(e)}")
    
    def _display_multi_file_visualizations(self, model_name: str):
        """æ˜¾ç¤ºå¤šæ–‡ä»¶æ±‡æ€»çš„å¯è§†åŒ–å›¾ç‰‡"""
        st.write("**ğŸ“ˆ å¤šæ–‡ä»¶æ±‡æ€»å¯è§†åŒ–å›¾è¡¨**")
        
        # ä½¿ç”¨FileManageræŸ¥æ‰¾æœ€æ–°çš„æ—¶é—´æˆ³ç›®å½•
        timestamped_dir = self.file_manager.find_latest_timestamp_dir(model_name)
        if not timestamped_dir:
            st.warning("âš ï¸ æœªæ‰¾åˆ°æ—¶é—´æˆ³ç›®å½•")
            return
        
        # å¤šæ–‡ä»¶æ±‡æ€»å›¾ç‰‡åœ¨multi_fileç›®å½•ä¸‹çš„visualizations
        viz_dir = timestamped_dir / "multi_file" / "visualizations"
        
        if not viz_dir.exists():
            st.warning("âš ï¸ æœªæ‰¾åˆ°å¤šæ–‡ä»¶æ±‡æ€»å¯è§†åŒ–å›¾ç‰‡ç›®å½•")
            return
        
        # æŸ¥æ‰¾å›¾ç‰‡æ–‡ä»¶
        image_files = []
        for ext in ['*.png', '*.jpg', '*.jpeg']:
            image_files.extend(viz_dir.glob(ext))
        
        if not image_files:
            st.warning("âš ï¸ æœªæ‰¾åˆ°å¤šæ–‡ä»¶æ±‡æ€»å¯è§†åŒ–å›¾ç‰‡")
            return
        
        # æ˜¾ç¤ºå›¾ç‰‡
        cols = st.columns(2)
        
        for i, image_path in enumerate(sorted(image_files)):
            try:
                image = Image.open(image_path)
                col_idx = i % 2
                
                with cols[col_idx]:
                    st.image(image, width=None)
                    # ä½¿ç”¨è‡ªå®šä¹‰HTMLæ˜¾ç¤ºæ›´å¤§çš„æ–‡ä»¶åæ ‡ç­¾
                    st.markdown(f"<p style='text-align: center; font-size: 16px; font-weight: bold; margin-top: 5px; color: #333;'>{image_path.stem}</p>", unsafe_allow_html=True)
            except Exception as e:
                st.error(f"âŒ æ— æ³•æ˜¾ç¤ºå›¾ç‰‡ {image_path.name}: {str(e)}")
    
    def _render_restart_button(self):
        """æ¸²æŸ“é‡æ–°å¼€å§‹æµ‹è¯„æŒ‰é’®ï¼ˆå¸¦ç¡®è®¤å¯¹è¯æ¡†ï¼‰"""
        st.subheader("ğŸ”„ é‡æ–°å¼€å§‹")

        st.write("ç‚¹å‡»ä¸‹æ–¹æŒ‰é’®é‡æ–°å¼€å§‹æµ‹è¯„ï¼ˆå°†æ¸…é™¤å½“å‰æ‰€æœ‰è¯„ä¼°æ•°æ®ï¼‰")

        # æ·»åŠ ç¡®è®¤æœºåˆ¶
        if 'show_restart_confirmation' not in st.session_state:
            st.session_state.show_restart_confirmation = False

        col1, col2, col3 = st.columns([1, 2, 1])

        with col2:
            if not st.session_state.show_restart_confirmation:
                # ç¬¬ä¸€æ­¥ï¼šç‚¹å‡»æŒ‰é’®æ˜¾ç¤ºç¡®è®¤æç¤º
                if st.button("ğŸ”„ é‡æ–°å¼€å§‹æµ‹è¯„", type="primary", use_container_width=True, key="restart_evaluation_button"):
                    st.session_state.show_restart_confirmation = True
                    st.rerun()
            else:
                # ç¬¬äºŒæ­¥ï¼šæ˜¾ç¤ºç¡®è®¤å¯¹è¯æ¡†
                st.warning("âš ï¸ ç¡®è®¤è¦é‡æ–°å¼€å§‹å—ï¼Ÿè¿™å°†æ¸…é™¤å½“å‰æ‰€æœ‰è¯„ä¼°æ•°æ®å’Œé…ç½®ã€‚")

                confirm_col1, confirm_col2 = st.columns(2)

                with confirm_col1:
                    if st.button("âœ… ç¡®è®¤é‡æ–°å¼€å§‹", type="primary", use_container_width=True, key="confirm_restart"):
                        # è·å–å½“å‰æ¨¡å‹åç§°å¹¶é‡ç½®FileManagerçš„æ—¶é—´æˆ³
                        current_model = st.session_state.get('selected_model', '')
                        if current_model:
                            reset_file_manager_for_new_test(current_model)

                        # æ¸…é™¤æ‰€æœ‰session state
                        keys_to_clear = [
                            'evaluation_params', 'evaluation_started', 'evaluation_running',
                            'evaluation_completed', 'evaluation_results', 'selected_files',
                            'newly_uploaded_files', 'current_timestamp', 'timestamped_model_name',
                            'info_completed', 'evaluation_info', 'selected_model',
                            'show_restart_confirmation'
                        ]

                        for key in keys_to_clear:
                            if key in st.session_state:
                                del st.session_state[key]

                        # æ¸…é™¤æ–‡ä»¶é€‰æ‹©çŠ¶æ€
                        keys_to_remove = []
                        for key in st.session_state.keys():
                            if key.startswith('file_'):
                                keys_to_remove.append(key)

                        for key in keys_to_remove:
                            del st.session_state[key]

                        # è®¾ç½®é‡ç½®æ ‡å¿—ï¼Œè®©file_uploadç•Œé¢æ˜¾ç¤ºä¿¡æ¯å¡«å†™ç•Œé¢
                        st.session_state.reset_to_initial_upload = True
                        st.session_state.show_info_form_in_upload = True

                        st.success("âœ… å·²é‡ç½®æ‰€æœ‰çŠ¶æ€ï¼Œè¯·é‡æ–°é…ç½®è¯„ä¼°å‚æ•°")
                        st.info("ğŸ’¡ ä¸‹æ¬¡å¼€å§‹æ–°æµ‹è¯•æ—¶å°†ç”Ÿæˆæ–°çš„æ—¶é—´æˆ³ç›®å½•")
                        st.info("ğŸ”„ è¯·åˆ‡æ¢åˆ°ã€Œæ–‡ä»¶ä¸Šä¼ ã€é€‰é¡¹å¡ï¼Œé¦–å…ˆé‡æ–°å¡«å†™è¯„ä¼°ä¿¡æ¯")
                        st.rerun()

                with confirm_col2:
                    if st.button("âŒ å–æ¶ˆ", use_container_width=True, key="cancel_restart"):
                        st.session_state.show_restart_confirmation = False
                        st.rerun()
    
    def _get_file_info_summary(self, model_name: str, file_names: List[str]) -> Dict[str, Any]:
        """è·å–æ–‡ä»¶ä¿¡æ¯æ‘˜è¦"""
        summary = {
            'total_files': len(file_names),
            'successful_files': 0,
            'failed_files': 0,
            'total_questions': 0,
            'total_correct': 0,
            'files_detail': []
        }
        
        # ä½¿ç”¨FileManageræŸ¥æ‰¾æœ€æ–°çš„æ—¶é—´æˆ³ç›®å½•
        timestamped_dir = self.file_manager.find_latest_timestamp_dir(model_name)
        if not timestamped_dir:
            return summary
        
        for file_name in file_names:
            analysis_path = timestamped_dir / file_name / f"{file_name}_analysis.json"
            
            file_info = {
                'name': file_name,
                'status': 'success' if analysis_path.exists() else 'failed',
                'questions': 0,
                'correct': 0,
                'accuracy': 0.0
            }
            
            if analysis_path.exists():
                try:
                    with open(analysis_path, 'r', encoding='utf-8') as f:
                        content = f.read().strip()
                        if not content:
                            continue  # è·³è¿‡ç©ºæ–‡ä»¶
                        data = json.loads(content)
                    
                    correct = data.get('final_correct_answers', 0)
                    reasoning_errors = data.get('final_reasoning_errors', 0)
                    knowledge_deficiency = data.get('final_knowledge_deficiency', 0)
                    capability_insufficient = data.get('final_capability_insufficient', 0)
                    
                    total_q = correct + reasoning_errors + knowledge_deficiency + capability_insufficient
                    
                    file_info.update({
                        'questions': total_q,
                        'correct': correct,
                        'accuracy': (correct / total_q * 100) if total_q > 0 else 0.0
                    })
                    
                    summary['successful_files'] += 1
                    summary['total_questions'] += total_q
                    summary['total_correct'] += correct
                    
                except Exception:
                    file_info['status'] = 'failed'
                    summary['failed_files'] += 1
            else:
                summary['failed_files'] += 1
            
            summary['files_detail'].append(file_info)
        
        return summary
    
    def _display_multi_file_analysis_table(self, analysis_data: Dict[str, Any], title: str):
        """æ˜¾ç¤ºå¤šæ–‡ä»¶æ±‡æ€»åˆ†æç»“æœè¡¨æ ¼ï¼ˆä¸æ˜¾ç¤ºè¯„ä¼°ç±»å‹ï¼‰"""
        st.write(f"**{title}**")
        
        # æ˜¾ç¤ºé‡è¦ä¿¡æ¯ï¼ˆå¤§å­—ä½“ï¼‰- åªæ˜¾ç¤ºæ–‡ä»¶åç§°å’Œæ–‡ä»¶æ•°é‡
        col1, col2 = st.columns(2)
        
        with col1:
            # æ˜¾ç¤ºå¤„ç†çš„æ–‡ä»¶åˆ—è¡¨
            if 'processed_files' in analysis_data:
                files_str = ", ".join(analysis_data['processed_files'])
                st.markdown(f"<div style='background-color: #f0f2f6; padding: 10px; border-radius: 5px; margin-bottom: 10px;'>"
                           f"<p style='font-size: 18px; font-weight: bold; margin: 0; color: #1f77b4;'>ğŸ“„ å¤„ç†æ–‡ä»¶</p>"
                           f"<p style='font-size: 16px; margin: 5px 0 0 0; color: #333;'>{files_str}</p>"
                           f"</div>", unsafe_allow_html=True)
        
        with col2:
            # æ˜¾ç¤ºæ–‡ä»¶æ•°é‡
            if 'file_count' in analysis_data:
                st.markdown(f"<div style='background-color: #f0f2f6; padding: 10px; border-radius: 5px; margin-bottom: 10px;'>"
                           f"<p style='font-size: 18px; font-weight: bold; margin: 0; color: #1f77b4;'>ğŸ“Š æ–‡ä»¶æ•°é‡</p>"
                           f"<p style='font-size: 16px; margin: 5px 0 0 0; color: #333;'>{analysis_data.get('file_count', 'N/A')}</p>"
                           f"</div>", unsafe_allow_html=True)
        
        # æ˜¾ç¤ºåŸºæœ¬ç»Ÿè®¡è¡¨æ ¼
        self._display_basic_statistics_table(analysis_data)
    
    def _display_variance_statistics(self, stage_name: str, stage_data: Dict[str, Any]):
        """æ˜¾ç¤ºæ–¹å·®ç»Ÿè®¡ä¿¡æ¯"""
        evaluation_summary = stage_data.get('evaluation_summary', {})
        
        if not evaluation_summary:
            return
        
        st.write(f"**ğŸ“ˆ {stage_name.upper()} è½®æ¬¡ç»Ÿè®¡åˆ†æ**")
        
        col1, col2, col3 = st.columns(3)
        
        # æœ€ä½³è½®æ¬¡
        best_round = evaluation_summary.get('best_round', {})
        if best_round:
            with col1:
                st.metric(
                    "æœ€ä½³è½®æ¬¡", 
                    f"ç¬¬{best_round.get('round', 'N/A')}è½®",
                    help="åŸºäºä¸»è¦æŒ‡æ ‡çš„æœ€ä½³è¡¨ç°è½®æ¬¡"
                )
        
        # æœ€å·®è½®æ¬¡
        worst_round = evaluation_summary.get('worst_round', {})
        if worst_round:
            with col2:
                st.metric(
                    "æœ€å·®è½®æ¬¡", 
                    f"ç¬¬{worst_round.get('round', 'N/A')}è½®",
                    help="åŸºäºä¸»è¦æŒ‡æ ‡çš„æœ€å·®è¡¨ç°è½®æ¬¡"
                )
        
        # æœ€ç¨³å®šæŒ‡æ ‡
        stable_metric = evaluation_summary.get('most_stable_metric', 'N/A')
        if stable_metric != 'N/A':
            with col3:
                metric_names = {
                    'accuracy_rate': 'å‡†ç¡®ç‡',
                    'reasoning_error_rate': 'æ¨ç†é”™è¯¯ç‡',
                    'retest_rate': 'é‡æµ‹ç‡',
                    'knowledge_deficiency_rate': 'çŸ¥è¯†ç¼ºå¤±ç‡',
                    'capability_insufficient_rate': 'èƒ½åŠ›ä¸è¶³ç‡'
                }
                display_name = metric_names.get(stable_metric, stable_metric)
                st.metric(
                    "æœ€ç¨³å®šæŒ‡æ ‡", 
                    display_name,
                    help="æ ‡å‡†å·®æœ€å°çš„è¯„ä¼°æŒ‡æ ‡"
                )