import json
import zipfile
from pathlib import Path
from typing import Dict, List, Any
from datetime import datetime
import io
import pandas as pd


class ReportGenerator:
    """è¯„ä¼°æŠ¥å‘Šç”Ÿæˆå™¨"""

    def __init__(self):
        pass

    def generate_analysis_report(self, analysis_data: Dict[str, Any]) -> str:
        """ç”Ÿæˆæ™ºèƒ½åˆ†ææŠ¥å‘Š

        Args:
            analysis_data: åˆ†ææ•°æ®

        Returns:
            str: Markdownæ ¼å¼çš„åˆ†ææŠ¥å‘Š
        """
        report = []

        # æ ‡é¢˜
        report.append("# ğŸ“Š LLM-as-judge è¯„ä¼°åˆ†ææŠ¥å‘Š\n")
        report.append(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        report.append("---\n")

        # åŸºæœ¬ä¿¡æ¯
        report.append("## ğŸ“‹ åŸºæœ¬ä¿¡æ¯\n")
        report.append(f"- **æ¨¡å‹åç§°**: {analysis_data.get('model_name', 'N/A')}")
        report.append(f"- **æ–‡ä»¶åç§°**: {analysis_data.get('file_name', 'N/A')}")

        eval_info = analysis_data.get('evaluation_info', {})
        if eval_info:
            rounds = eval_info.get('evaluation_rounds', 1)
            # æ ¹æ®å®é™…è½®æ¬¡åˆ¤æ–­ï¼šè½®æ¬¡å¤§äº1æ‰æ˜¯å¤šè½®è¯„ä¼°
            is_multi_round = rounds > 1
            report.append(f"- **è¯„ä¼°æ¨¡å¼**: {'å¤šè½®è¯„ä¼°' if is_multi_round else 'å•è½®è¯„ä¼°'}")
            if is_multi_round:
                report.append(f"- **è¯„ä¼°è½®æ¬¡**: {rounds} è½®")

        report.append("\n---\n")

        # æ•´ä½“è¡¨ç°
        report.append("## ğŸ¯ æ•´ä½“è¡¨ç°æ€»ç»“\n")

        total_questions = analysis_data.get('total_questions', 0)
        correct_answers = analysis_data.get('final_correct_answers', 0)
        reasoning_errors = analysis_data.get('final_reasoning_errors', 0)
        knowledge_deficiency = analysis_data.get('final_knowledge_deficiency', 0)
        capability_insufficient = analysis_data.get('final_capability_insufficient', 0)

        accuracy_rate = analysis_data.get('final_accuracy_rate', 0)

        report.append(f"### ğŸ“ˆ å…³é”®æŒ‡æ ‡\n")
        report.append(f"- **æ€»é—®é¢˜æ•°**: {total_questions}")
        report.append(f"- **æ­£ç¡®å›ç­”**: {correct_answers} ({accuracy_rate:.2f}%)")
        report.append(f"- **æ¨ç†é”™è¯¯**: {reasoning_errors}")
        report.append(f"- **çŸ¥è¯†ç¼ºå¤±**: {knowledge_deficiency}")
        report.append(f"- **èƒ½åŠ›ä¸è¶³**: {capability_insufficient}\n")

        # æ€§èƒ½ç­‰çº§è¯„ä¼°
        report.append("### â­ æ€§èƒ½ç­‰çº§\n")
        performance_level = self._get_performance_level(accuracy_rate)
        report.append(f"**{performance_level['emoji']} {performance_level['level']}**\n")
        report.append(f"_{performance_level['description']}_\n")

        report.append("\n---\n")

        # è¯¦ç»†åˆ†æ
        report.append("## ğŸ” è¯¦ç»†åˆ†æ\n")

        # ä¼˜åŠ¿åˆ†æ
        report.append("### âœ… ä¼˜åŠ¿è¡¨ç°\n")
        strengths = self._analyze_strengths(analysis_data)
        for strength in strengths:
            report.append(f"- {strength}")
        report.append("")

        # é—®é¢˜åˆ†æ
        report.append("### âš ï¸ é—®é¢˜åˆ†æ\n")
        weaknesses = self._analyze_weaknesses(analysis_data)
        for weakness in weaknesses:
            report.append(f"- {weakness}")
        report.append("")

        # æ”¹è¿›å»ºè®®
        report.append("### ğŸ’¡ æ”¹è¿›å»ºè®®\n")
        suggestions = self._generate_suggestions(analysis_data)
        for i, suggestion in enumerate(suggestions, 1):
            report.append(f"{i}. {suggestion}")
        report.append("")

        report.append("\n---\n")

        # é˜¶æ®µæ€§åˆ†æ
        report.append("## ğŸ“Š é˜¶æ®µæ€§è¡¨ç°\n")

        # Stage1åˆ†æ
        stage1_stats = analysis_data.get('stage1', {}).get('statistics', {})
        if stage1_stats:
            report.append("### Stage1 - åŸºç¡€é—®ç­”\n")
            report.append(f"- æ­£ç¡®ç‡: {stage1_stats.get('accuracy_rate', 0):.2f}%")
            report.append(f"- éœ€è¦é‡æµ‹: {stage1_stats.get('need_retest', 0)} é¢˜")
            report.append(f"- é‡æµ‹ç‡: {stage1_stats.get('retest_rate', 0):.2f}%\n")

        # Stage2åˆ†æ
        stage2_stats = analysis_data.get('stage2', {}).get('statistics', {})
        if stage2_stats and stage2_stats.get('total_questions', 0) > 0:
            report.append("### Stage2 - æ·±åº¦è¯„ä¼°\n")
            report.append(f"- å¤„ç†é—®é¢˜: {stage2_stats.get('total_questions', 0)} é¢˜")
            report.append(f"- çŸ¥è¯†ç¼ºå¤±: {stage2_stats.get('knowledge_deficiency', 0)} é¢˜")
            report.append(f"- æ¨ç†é”™è¯¯: {stage2_stats.get('reasoning_errors', 0)} é¢˜")
            report.append(f"- èƒ½åŠ›ä¸è¶³: {stage2_stats.get('capability_insufficient', 0)} é¢˜\n")

        report.append("\n---\n")

        # ç»“è®º
        report.append("## ğŸ“ ç»“è®º\n")
        conclusion = self._generate_conclusion(analysis_data)
        report.append(conclusion)
        report.append("\n")

        report.append("---\n")
        report.append("_æœ¬æŠ¥å‘Šç”± LLM-as-judge è¯„ä¼°ç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆ_")

        return "\n".join(report)

    def _get_performance_level(self, accuracy_rate: float) -> Dict[str, str]:
        """æ ¹æ®å‡†ç¡®ç‡è¯„å®šæ€§èƒ½ç­‰çº§"""
        if accuracy_rate >= 90:
            return {
                'emoji': 'ğŸ†',
                'level': 'å“è¶Š (Excellent)',
                'description': 'æ¨¡å‹è¡¨ç°å‡ºè‰²ï¼Œå‡†ç¡®ç‡è¶…è¿‡90%ï¼Œè¾¾åˆ°äº†ä¼˜ç§€æ°´å¹³ã€‚'
            }
        elif accuracy_rate >= 75:
            return {
                'emoji': 'ğŸ¥‡',
                'level': 'è‰¯å¥½ (Good)',
                'description': 'æ¨¡å‹è¡¨ç°è‰¯å¥½ï¼Œå‡†ç¡®ç‡åœ¨75%-90%ä¹‹é—´ï¼Œæœ‰ä¸€å®šçš„æå‡ç©ºé—´ã€‚'
            }
        elif accuracy_rate >= 60:
            return {
                'emoji': 'ğŸ¥ˆ',
                'level': 'ä¸­ç­‰ (Fair)',
                'description': 'æ¨¡å‹è¡¨ç°ä¸­ç­‰ï¼Œå‡†ç¡®ç‡åœ¨60%-75%ä¹‹é—´ï¼Œéœ€è¦æ”¹è¿›ã€‚'
            }
        elif accuracy_rate >= 40:
            return {
                'emoji': 'ğŸ¥‰',
                'level': 'åŠæ ¼ (Passing)',
                'description': 'æ¨¡å‹åŸºæœ¬è¾¾åˆ°åŠæ ¼çº¿ï¼Œå‡†ç¡®ç‡åœ¨40%-60%ä¹‹é—´ï¼Œæœ‰è¾ƒå¤§æ”¹è¿›ç©ºé—´ã€‚'
            }
        else:
            return {
                'emoji': 'âš ï¸',
                'level': 'éœ€è¦æ”¹è¿› (Needs Improvement)',
                'description': 'æ¨¡å‹è¡¨ç°ä¸ä½³ï¼Œå‡†ç¡®ç‡ä½äº40%ï¼Œå»ºè®®é‡ç‚¹ä¼˜åŒ–ã€‚'
            }

    def _analyze_strengths(self, analysis_data: Dict[str, Any]) -> List[str]:
        """åˆ†æä¼˜åŠ¿"""
        strengths = []

        accuracy_rate = analysis_data.get('final_accuracy_rate', 0)
        reasoning_error_rate = analysis_data.get('final_reasoning_error_rate', 0)
        knowledge_deficiency_rate = analysis_data.get('final_knowledge_deficiency_rate', 0)

        if accuracy_rate >= 75:
            strengths.append(f"**é«˜å‡†ç¡®ç‡**: æ¨¡å‹è¾¾åˆ°äº† {accuracy_rate:.2f}% çš„å‡†ç¡®ç‡ï¼Œè¡¨ç°ä¼˜ç§€")

        if reasoning_error_rate < 10:
            strengths.append(f"**æ¨ç†èƒ½åŠ›å¼º**: æ¨ç†é”™è¯¯ç‡ä»…ä¸º {reasoning_error_rate:.2f}%ï¼Œé€»è¾‘æ¨ç†èƒ½åŠ›çªå‡º")

        if knowledge_deficiency_rate < 15:
            strengths.append(f"**çŸ¥è¯†è¦†ç›–å¹¿**: çŸ¥è¯†ç¼ºå¤±ç‡ä¸º {knowledge_deficiency_rate:.2f}%ï¼ŒçŸ¥è¯†åº“è¾ƒä¸ºå®Œå–„")

        # Stage1è¡¨ç°
        stage1_accuracy = analysis_data.get('stage1', {}).get('statistics', {}).get('accuracy_rate', 0)
        if stage1_accuracy >= 70:
            strengths.append(f"**åŸºç¡€é—®ç­”èƒ½åŠ›å¼º**: Stage1å‡†ç¡®ç‡è¾¾åˆ° {stage1_accuracy:.2f}%")

        if not strengths:
            strengths.append("æ¨¡å‹åœ¨å„é¡¹æŒ‡æ ‡ä¸­è¡¨ç°ç¨³å®šï¼Œå…·å¤‡åŸºç¡€çš„é—®ç­”èƒ½åŠ›")

        return strengths

    def _analyze_weaknesses(self, analysis_data: Dict[str, Any]) -> List[str]:
        """åˆ†æé—®é¢˜"""
        weaknesses = []

        reasoning_error_rate = analysis_data.get('final_reasoning_error_rate', 0)
        knowledge_deficiency_rate = analysis_data.get('final_knowledge_deficiency_rate', 0)
        capability_insufficient_rate = analysis_data.get('final_capability_insufficient_rate', 0)
        accuracy_rate = analysis_data.get('final_accuracy_rate', 0)

        if accuracy_rate < 60:
            weaknesses.append(f"**å‡†ç¡®ç‡åä½**: æ•´ä½“å‡†ç¡®ç‡ä»…ä¸º {accuracy_rate:.2f}%ï¼Œéœ€è¦é‡ç‚¹æå‡")

        if reasoning_error_rate > 20:
            weaknesses.append(f"**æ¨ç†èƒ½åŠ›ä¸è¶³**: æ¨ç†é”™è¯¯ç‡é«˜è¾¾ {reasoning_error_rate:.2f}%ï¼Œé€»è¾‘æ¨ç†éœ€è¦åŠ å¼º")
        elif reasoning_error_rate > 10:
            weaknesses.append(f"**æ¨ç†é”™è¯¯è¾ƒå¤š**: æ¨ç†é”™è¯¯ç‡ä¸º {reasoning_error_rate:.2f}%ï¼Œå­˜åœ¨æ”¹è¿›ç©ºé—´")

        if knowledge_deficiency_rate > 25:
            weaknesses.append(f"**çŸ¥è¯†è¦†ç›–ä¸è¶³**: çŸ¥è¯†ç¼ºå¤±ç‡ä¸º {knowledge_deficiency_rate:.2f}%ï¼ŒçŸ¥è¯†åº“éœ€è¦æ‰©å……")
        elif knowledge_deficiency_rate > 15:
            weaknesses.append(f"**éƒ¨åˆ†çŸ¥è¯†ç›²åŒº**: çŸ¥è¯†ç¼ºå¤±ç‡ä¸º {knowledge_deficiency_rate:.2f}%ï¼Œå»ºè®®è¡¥å……ç›¸å…³çŸ¥è¯†")

        if capability_insufficient_rate > 15:
            weaknesses.append(f"**èƒ½åŠ›é™åˆ¶**: èƒ½åŠ›ä¸è¶³ç‡ä¸º {capability_insufficient_rate:.2f}%ï¼Œæ¨¡å‹èƒ½åŠ›éœ€è¦æå‡")

        # Stage1é‡æµ‹ç‡åˆ†æ
        retest_rate = analysis_data.get('stage1', {}).get('statistics', {}).get('retest_rate', 0)
        if retest_rate > 30:
            weaknesses.append(f"**é¦–è½®é€šè¿‡ç‡ä½**: Stage1é‡æµ‹ç‡é«˜è¾¾ {retest_rate:.2f}%ï¼ŒåŸºç¡€é—®ç­”èƒ½åŠ›æœ‰å¾…æé«˜")

        if not weaknesses:
            weaknesses.append("æœªå‘ç°æ˜¾è‘—é—®é¢˜ï¼Œæ¨¡å‹æ•´ä½“è¡¨ç°è‰¯å¥½")

        return weaknesses

    def _generate_suggestions(self, analysis_data: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        suggestions = []

        reasoning_error_rate = analysis_data.get('final_reasoning_error_rate', 0)
        knowledge_deficiency_rate = analysis_data.get('final_knowledge_deficiency_rate', 0)
        capability_insufficient_rate = analysis_data.get('final_capability_insufficient_rate', 0)
        accuracy_rate = analysis_data.get('final_accuracy_rate', 0)

        # æ ¹æ®ä¸åŒé—®é¢˜ç»™å‡ºé’ˆå¯¹æ€§å»ºè®®
        if accuracy_rate < 60:
            suggestions.append("**æ•´ä½“ä¼˜åŒ–**: è€ƒè™‘ä½¿ç”¨æ›´å¤§è§„æ¨¡çš„è®­ç»ƒæ•°æ®é›†ï¼Œæˆ–å‡çº§åˆ°å‚æ•°é‡æ›´å¤§çš„æ¨¡å‹ç‰ˆæœ¬")

        if knowledge_deficiency_rate > 20:
            suggestions.append("**çŸ¥è¯†å¢å¼º**: æ‰©å……è®­ç»ƒè¯­æ–™ï¼Œç‰¹åˆ«æ˜¯åœ¨çŸ¥è¯†ç¼ºå¤±è¾ƒå¤šçš„é¢†åŸŸè¡¥å……ä¸“ä¸šçŸ¥è¯†")
            suggestions.append("**RAGé›†æˆ**: è€ƒè™‘é›†æˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ç³»ç»Ÿï¼ŒåŠ¨æ€è¡¥å……å¤–éƒ¨çŸ¥è¯†")

        if reasoning_error_rate > 15:
            suggestions.append("**æ¨ç†è®­ç»ƒ**: å¢åŠ é€»è¾‘æ¨ç†å’Œæ€ç»´é“¾ï¼ˆChain-of-Thoughtï¼‰è®­ç»ƒæ ·æœ¬")
            suggestions.append("**æç¤ºè¯ä¼˜åŒ–**: ä¼˜åŒ–promptè®¾è®¡ï¼Œå¼•å¯¼æ¨¡å‹è¿›è¡Œæ›´ä¸¥è°¨çš„é€»è¾‘æ¨ç†")

        if capability_insufficient_rate > 15:
            suggestions.append("**æ¨¡å‹å‡çº§**: è€ƒè™‘ä½¿ç”¨èƒ½åŠ›æ›´å¼ºçš„æ¨¡å‹æˆ–è¿›è¡Œé’ˆå¯¹æ€§çš„å¾®è°ƒï¼ˆFine-tuningï¼‰")

        # é€šç”¨å»ºè®®
        retest_rate = analysis_data.get('stage1', {}).get('statistics', {}).get('retest_rate', 0)
        if retest_rate > 25:
            suggestions.append("**åŸºç¡€èƒ½åŠ›å¼ºåŒ–**: Stage1é‡æµ‹ç‡è¾ƒé«˜ï¼Œå»ºè®®é‡ç‚¹æå‡åŸºç¡€é—®ç­”èƒ½åŠ›")

        if accuracy_rate >= 75:
            suggestions.append("**æŒç»­ç›‘æ§**: æ¨¡å‹è¡¨ç°è‰¯å¥½ï¼Œå»ºè®®æŒç»­ç›‘æ§æ€§èƒ½ï¼Œå®šæœŸè¯„ä¼°æ–°æ•°æ®é›†")
            suggestions.append("**è¾¹ç•Œæµ‹è¯•**: å°è¯•æ›´å…·æŒ‘æˆ˜æ€§çš„æµ‹è¯•ç”¨ä¾‹ï¼Œæ¢ç´¢æ¨¡å‹çš„èƒ½åŠ›è¾¹ç•Œ")

        if not suggestions:
            suggestions.append("æ¨¡å‹è¡¨ç°ç¨³å®šï¼Œå»ºè®®ç»§ç»­ä¿æŒå½“å‰è®­ç»ƒç­–ç•¥")

        return suggestions

    def _generate_conclusion(self, analysis_data: Dict[str, Any]) -> str:
        """ç”Ÿæˆç»“è®º"""
        accuracy_rate = analysis_data.get('final_accuracy_rate', 0)
        total_questions = analysis_data.get('total_questions', 0)
        correct_answers = analysis_data.get('final_correct_answers', 0)

        conclusion = f"åœ¨æœ¬æ¬¡è¯„ä¼°ä¸­ï¼Œæ¨¡å‹å…±å¤„ç†äº† **{total_questions}** ä¸ªé—®é¢˜ï¼Œ"
        conclusion += f"æ­£ç¡®å›ç­”äº† **{correct_answers}** ä¸ªï¼Œæ•´ä½“å‡†ç¡®ç‡ä¸º **{accuracy_rate:.2f}%**ã€‚"

        if accuracy_rate >= 75:
            conclusion += " æ¨¡å‹è¡¨ç°**è‰¯å¥½**ï¼Œå·²è¾¾åˆ°å®ç”¨æ°´å¹³ã€‚"
        elif accuracy_rate >= 60:
            conclusion += " æ¨¡å‹è¡¨ç°**å°šå¯**ï¼Œä½†ä»æœ‰è¾ƒå¤§æå‡ç©ºé—´ã€‚"
        else:
            conclusion += " æ¨¡å‹è¡¨ç°**éœ€è¦æ”¹è¿›**ï¼Œå»ºè®®é‡ç‚¹ä¼˜åŒ–ã€‚"

        # ä¸»è¦é—®é¢˜æ€»ç»“
        reasoning_error_rate = analysis_data.get('final_reasoning_error_rate', 0)
        knowledge_deficiency_rate = analysis_data.get('final_knowledge_deficiency_rate', 0)

        main_issues = []
        if reasoning_error_rate > 15:
            main_issues.append("æ¨ç†èƒ½åŠ›")
        if knowledge_deficiency_rate > 20:
            main_issues.append("çŸ¥è¯†è¦†ç›–")

        if main_issues:
            conclusion += f" ä¸»è¦æ”¹è¿›æ–¹å‘åº”èšç„¦åœ¨**{'ã€'.join(main_issues)}**æ–¹é¢ã€‚"

        return conclusion

    def create_download_package(self, model_name: str, file_names: List[str],
                               timestamped_dir: Path) -> io.BytesIO:
        """åˆ›å»ºå¯ä¸‹è½½çš„æ‰“åŒ…æ–‡ä»¶

        Args:
            model_name: æ¨¡å‹åç§°
            file_names: æ–‡ä»¶ååˆ—è¡¨
            timestamped_dir: æ—¶é—´æˆ³ç›®å½•

        Returns:
            io.BytesIO: ZIPæ–‡ä»¶çš„å­—èŠ‚æµ
        """
        zip_buffer = io.BytesIO()

        with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
            # æ·»åŠ åˆ†ææŠ¥å‘Š
            for file_name in file_names:
                analysis_path = timestamped_dir / file_name / f"{file_name}_analysis.json"
                if analysis_path.exists():
                    with open(analysis_path, 'r', encoding='utf-8') as f:
                        analysis_data = json.load(f)

                    # ç”ŸæˆMarkdownæŠ¥å‘Š
                    report_md = self.generate_analysis_report(analysis_data)
                    zip_file.writestr(f"reports/{file_name}_report.md", report_md)

                    # æ·»åŠ åŸå§‹JSON
                    zip_file.write(analysis_path, f"data/{file_name}_analysis.json")

            # æ·»åŠ å¯è§†åŒ–å›¾ç‰‡
            for file_name in file_names:
                viz_dir = timestamped_dir / file_name / "visualizations"
                if viz_dir.exists():
                    for img_file in viz_dir.glob("*.png"):
                        zip_file.write(img_file, f"visualizations/{file_name}/{img_file.name}")

            # æ·»åŠ å¤šæ–‡ä»¶æ±‡æ€»ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            multi_file_dir = timestamped_dir / "multi_file"
            if multi_file_dir.exists():
                multi_analysis = multi_file_dir / "multi_analysis.json"
                if multi_analysis.exists():
                    zip_file.write(multi_analysis, "data/multi_file_analysis.json")

                multi_viz = multi_file_dir / "visualizations"
                if multi_viz.exists():
                    for img_file in multi_viz.glob("*.png"):
                        zip_file.write(img_file, f"visualizations/multi_file/{img_file.name}")

            # æ·»åŠ README
            readme = self._generate_readme(model_name, file_names)
            zip_file.writestr("README.md", readme)

        zip_buffer.seek(0)
        return zip_buffer

    def _generate_readme(self, model_name: str, file_names: List[str]) -> str:
        """ç”ŸæˆREADMEæ–‡ä»¶"""
        readme = []
        readme.append("# LLM-as-judge è¯„ä¼°æŠ¥å‘ŠåŒ…\n")
        readme.append(f"**æ¨¡å‹åç§°**: {model_name}")
        readme.append(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        readme.append(f"**æ–‡ä»¶æ•°é‡**: {len(file_names)}\n")

        readme.append("## ğŸ“ æ–‡ä»¶ç»“æ„\n")
        readme.append("```")
        readme.append("â”œâ”€â”€ README.md                 # æœ¬æ–‡ä»¶")
        readme.append("â”œâ”€â”€ reports/                  # åˆ†ææŠ¥å‘Šï¼ˆMarkdownæ ¼å¼ï¼‰")
        for file_name in file_names:
            readme.append(f"â”‚   â””â”€â”€ {file_name}_report.md")
        readme.append("â”œâ”€â”€ data/                     # åŸå§‹æ•°æ®ï¼ˆJSONæ ¼å¼ï¼‰")
        for file_name in file_names:
            readme.append(f"â”‚   â”œâ”€â”€ {file_name}_analysis.json")
        readme.append("â”‚   â””â”€â”€ multi_file_analysis.json  # å¤šæ–‡ä»¶æ±‡æ€»")
        readme.append("â””â”€â”€ visualizations/           # å¯è§†åŒ–å›¾è¡¨")
        for file_name in file_names:
            readme.append(f"    â””â”€â”€ {file_name}/")
        readme.append("        â””â”€â”€ multi_file/       # å¤šæ–‡ä»¶æ±‡æ€»å›¾è¡¨")
        readme.append("```\n")

        readme.append("## ğŸ“– ä½¿ç”¨è¯´æ˜\n")
        readme.append("1. **æŸ¥çœ‹æŠ¥å‘Š**: æ‰“å¼€ `reports/` ç›®å½•ä¸‹çš„ Markdown æ–‡ä»¶")
        readme.append("2. **æŸ¥çœ‹æ•°æ®**: `data/` ç›®å½•åŒ…å«å®Œæ•´çš„JSONæ•°æ®")
        readme.append("3. **æŸ¥çœ‹å›¾è¡¨**: `visualizations/` ç›®å½•åŒ…å«æ‰€æœ‰å¯è§†åŒ–å›¾è¡¨\n")

        readme.append("## ğŸ“Š æŠ¥å‘Šè¯´æ˜\n")
        readme.append("æ¯ä¸ªæŠ¥å‘ŠåŒ…å«ä»¥ä¸‹å†…å®¹ï¼š")
        readme.append("- ğŸ“‹ åŸºæœ¬ä¿¡æ¯")
        readme.append("- ğŸ¯ æ•´ä½“è¡¨ç°æ€»ç»“")
        readme.append("- ğŸ” è¯¦ç»†åˆ†æï¼ˆä¼˜åŠ¿ã€é—®é¢˜ã€å»ºè®®ï¼‰")
        readme.append("- ğŸ“Š é˜¶æ®µæ€§è¡¨ç°")
        readme.append("- ğŸ“ ç»“è®º\n")

        readme.append("---")
        readme.append("_ç”± LLM-as-judge è¯„ä¼°ç³»ç»Ÿç”Ÿæˆ_")

        return "\n".join(readme)
